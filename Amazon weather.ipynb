{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "т.к. маркеры погоды не пересекаются, то имеет смысл обучить отдельный алгоритм для этих маркеров, а для остальных использовать другие алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PathDetermination(user):\n",
    "    if user == 'litvin_home':\n",
    "        core_dir = 'C:\\\\Kaggle\\\\Understanding the Amazon from Space\\\\'\n",
    "    \n",
    "    if user == 'litvin_office':\n",
    "        core_dir = 'D:\\\\Kaggle\\\\Understanding the Amazon from Space\\\\'\n",
    "        train_dir = core_dir + 'train-jpg\\\\'\n",
    "        test_dir = core_dir + 'test-jpg\\\\'\n",
    "        add_test_dir = core_dir + 'test-jpg-additional\\\\'\n",
    "    \n",
    "    if user == 'savina':\n",
    "        core_dir = 'Z:\\\\Kaggle Amazon Rainforest\\\\'\n",
    "        train_dir = ''\n",
    "        test_dir = 'C:\\\\Users\\\\horch\\\\Desktop\\\\Local_data\\\\test-jpg\\\\'\n",
    "        add_test_dir = 'C:\\\\Users\\\\horch\\\\Desktop\\\\Local_data\\\\test-jpg-additional\\\\'\n",
    "    \n",
    "    return core_dir, train_dir, test_dir, add_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_dir, train_dir, test_dir, add_test_dir = PathDetermination('litvin_office')\n",
    "#core_dir, test_dir, add_test_dir = path_determination('savina')\n",
    "\n",
    "test_data_names = natsorted(os.listdir(test_dir), key=lambda y: y.lower())\n",
    "add_test_data_names = os.listdir(add_test_dir)\n",
    "\n",
    "\n",
    "cathegories = ['agriculture', 'artisinal_mine', 'bare_ground', \n",
    "                      'blooming', 'blow_down', 'clear', 'cloudy', 'conventional_mine', \n",
    "                      'cultivation', 'habitation', 'haze', 'partly_cloudy', 'primary', \n",
    "                      'road', 'selective_logging', 'slash_burn', 'water']\n",
    "\n",
    "weather_cathegories = ['clear', 'cloudy', 'haze', 'partly_cloudy']\n",
    "\n",
    "train_data = pd.read_csv(core_dir + 'train_v2.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BinimialPrediction(X, treshold = 0.5):\n",
    "    result = np.zeros(X.shape)\n",
    "    \n",
    "    if type(treshold) == int or type(treshold) == float:\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                if X[i, j] >= treshold:\n",
    "                    result[i, j] = 1\n",
    "    elif type(treshold) == list:\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                if X[i, j] >= treshold[j]:\n",
    "                    result[i, j] = 1\n",
    "    else:\n",
    "        print('treshold type must be int, float or list')\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "def FBettaScore(x_true, x_predicted, betta = 2):\n",
    "    if len(x_true) == len(x_predicted):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for i in range(len(x_predicted)):\n",
    "            if x_true[i] == 1 and x_predicted[i] == 1:\n",
    "                tp += 1\n",
    "            \n",
    "            if x_true[i] == 0 and x_predicted[i] == 1:\n",
    "                fp += 1\n",
    "            \n",
    "            if x_true[i] == 1 and x_predicted[i] == 0:\n",
    "                fn += 1\n",
    "        \n",
    "        if tp == 0 or (tp + fp) == 0 or (tp + fn) == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            precision = tp/(tp + fp)\n",
    "            recall = tp/(tp + fn)\n",
    "            \n",
    "            return((1 + betta**2)*precision*recall/(betta**2*precision + recall))\n",
    "    else:\n",
    "        print('FBettaScore error! len(x_true) != len(x_predicted)')\n",
    "\n",
    "def AvgFBettaScore(x_true, x_predicted, betta = 2, treshold = 0.5):\n",
    "    result = 0\n",
    "    n = x_true.shape[0]\n",
    "    \n",
    "    x_predicted = BinimialPrediction(x_predicted, treshold)\n",
    "    \n",
    "    for i in range(n):\n",
    "        result += FBettaScore(x_true[i, :], x_predicted[i, :], betta)\n",
    "    \n",
    "    return(result/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataPreperation(data_type, img_size = (32, 32), rotation = [0], \n",
    "                    test_img_dir = [test_dir, add_test_dir], shuffle = False):\n",
    "    if data_type == 'train':\n",
    "        X = []\n",
    "        Y = []\n",
    "        \n",
    "        for img_name in tqdm(train_data.image_name.values):\n",
    "    \n",
    "            img = cv2.imread(train_dir + img_name + '.jpg')\n",
    "            img_resized = cv2.resize(img, img_size)\n",
    "            \n",
    "            img_tags = train_data[train_data['image_name'] == img_name]['tags'].values[0].split(' ')\n",
    "            y = np.zeros(len(cathegories))\n",
    "            \n",
    "            for i in range(len(y)):\n",
    "                if cathegories[i] in img_tags:\n",
    "                    y[i] = 1\n",
    "            \n",
    "            for angle in rotation:\n",
    "                img = imutils.rotate(img_resized, angle)\n",
    "                X.append(img)\n",
    "                Y.append(y) \n",
    "        \n",
    "        X = np.array(X, np.float16) / 255.\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        if shuffle:\n",
    "            ind = np.random.choice(np.arange(X.shape[0]), X.shape[0], replace= False)\n",
    "            X = X[ind]\n",
    "            Y = Y[ind]\n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "    if data_type == 'test':\n",
    "        X_test = []\n",
    "        X_test_names = []\n",
    "\n",
    "        for img_dir in test_img_dir:\n",
    "            img_dir_names = os.listdir(img_dir)\n",
    "            \n",
    "            for img_name in tqdm(img_dir_names):\n",
    "                if img_name.endswith(\"jpg\"):\n",
    "                    img = cv2.imread(img_dir + img_name)\n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    \n",
    "                    X_test.append(img)\n",
    "                    X_test_names.append(img_name)\n",
    "    \n",
    "        X_test = np.array(X_test, np.float16) / 255.\n",
    "        \n",
    "        return X_test, X_test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 40479/40479 [12:23<00:00, 54.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X, Y = DataPreperation('train', rotation = [0], shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_weather = Y[:, [cathegories.index(x) for x in weather_cathegories]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits= 1, test_size= 0.3, random_state= 42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, Y_weather):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_weather[train_index], Y_weather[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка и  обучение сети для погоды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 64\n",
    "drop_prob_1 = 0.25\n",
    "drop_prob_2 = 0.5\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = X.shape[0]\n",
    "depth = 32 \n",
    "height = 32\n",
    "width = 3 \n",
    "\n",
    "num_classes = len(weather_cathegories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras!\n",
    "\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "\n",
    "flat = Flatten()(drop_2)\n",
    "\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(input=inp, output=out)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28335 samples, validate on 12144 samples\n",
      "Epoch 1/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.6871 - acc: 0.7319 - val_loss: 0.5886 - val_acc: 0.7918\n",
      "Epoch 2/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.4962 - acc: 0.8156 - val_loss: 0.4926 - val_acc: 0.8145\n",
      "Epoch 3/50\n",
      "28335/28335 [==============================] - 163s - loss: 0.3980 - acc: 0.8564 - val_loss: 0.3817 - val_acc: 0.8593\n",
      "Epoch 4/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.3479 - acc: 0.8763 - val_loss: 0.3398 - val_acc: 0.8745\n",
      "Epoch 5/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.3087 - acc: 0.8884 - val_loss: 0.5131 - val_acc: 0.8152\n",
      "Epoch 6/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.2963 - acc: 0.8925 - val_loss: 0.2804 - val_acc: 0.8954\n",
      "Epoch 7/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.2717 - acc: 0.8999 - val_loss: 0.2818 - val_acc: 0.8953\n",
      "Epoch 8/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.2632 - acc: 0.9020 - val_loss: 0.3044 - val_acc: 0.8931\n",
      "Epoch 9/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.2538 - acc: 0.9073 - val_loss: 0.2366 - val_acc: 0.9144\n",
      "Epoch 10/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.2388 - acc: 0.9095 - val_loss: 0.2411 - val_acc: 0.9120\n",
      "Epoch 11/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.2325 - acc: 0.9123 - val_loss: 0.2455 - val_acc: 0.9090\n",
      "Epoch 12/50\n",
      "28335/28335 [==============================] - 158s - loss: 0.2221 - acc: 0.9166 - val_loss: 0.2251 - val_acc: 0.9143\n",
      "Epoch 13/50\n",
      "28335/28335 [==============================] - 158s - loss: 0.2167 - acc: 0.9161 - val_loss: 0.2320 - val_acc: 0.9126\n",
      "Epoch 14/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.2047 - acc: 0.9209 - val_loss: 0.2153 - val_acc: 0.9187\n",
      "Epoch 15/50\n",
      "28335/28335 [==============================] - 163s - loss: 0.1971 - acc: 0.9224 - val_loss: 0.2119 - val_acc: 0.9232\n",
      "Epoch 16/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.1986 - acc: 0.9216 - val_loss: 0.2342 - val_acc: 0.9180\n",
      "Epoch 17/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1804 - acc: 0.9285 - val_loss: 0.2192 - val_acc: 0.9238\n",
      "Epoch 18/50\n",
      "28335/28335 [==============================] - 168s - loss: 0.1794 - acc: 0.9283 - val_loss: 0.3067 - val_acc: 0.8939\n",
      "Epoch 19/50\n",
      "28335/28335 [==============================] - 169s - loss: 0.1749 - acc: 0.9314 - val_loss: 0.2218 - val_acc: 0.9218\n",
      "Epoch 20/50\n",
      "28335/28335 [==============================] - 163s - loss: 0.1631 - acc: 0.9356 - val_loss: 0.2306 - val_acc: 0.9215\n",
      "Epoch 21/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1600 - acc: 0.9367 - val_loss: 0.2272 - val_acc: 0.9286\n",
      "Epoch 22/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1514 - acc: 0.9401 - val_loss: 0.2394 - val_acc: 0.9209\n",
      "Epoch 23/50\n",
      "28335/28335 [==============================] - 158s - loss: 0.1466 - acc: 0.9431 - val_loss: 0.2546 - val_acc: 0.9079\n",
      "Epoch 24/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.1474 - acc: 0.9418 - val_loss: 0.2289 - val_acc: 0.9236\n",
      "Epoch 25/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.1403 - acc: 0.9446 - val_loss: 0.2360 - val_acc: 0.9240\n",
      "Epoch 26/50\n",
      "28335/28335 [==============================] - 169s - loss: 0.1364 - acc: 0.9462 - val_loss: 0.2204 - val_acc: 0.9304\n",
      "Epoch 27/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.1353 - acc: 0.9467 - val_loss: 0.2295 - val_acc: 0.9287\n",
      "Epoch 28/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1253 - acc: 0.9525 - val_loss: 0.2209 - val_acc: 0.9376\n",
      "Epoch 29/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1219 - acc: 0.9537 - val_loss: 0.2342 - val_acc: 0.9326\n",
      "Epoch 30/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.1194 - acc: 0.9536 - val_loss: 0.2576 - val_acc: 0.9249\n",
      "Epoch 31/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.1231 - acc: 0.9522 - val_loss: 0.2296 - val_acc: 0.9382\n",
      "Epoch 32/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.1180 - acc: 0.9546 - val_loss: 0.2472 - val_acc: 0.9301\n",
      "Epoch 33/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.1064 - acc: 0.9582 - val_loss: 0.2377 - val_acc: 0.9370\n",
      "Epoch 34/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.1072 - acc: 0.9585 - val_loss: 0.2517 - val_acc: 0.9321\n",
      "Epoch 35/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1030 - acc: 0.9611 - val_loss: 0.2337 - val_acc: 0.9377\n",
      "Epoch 36/50\n",
      "28335/28335 [==============================] - 158s - loss: 0.0992 - acc: 0.9617 - val_loss: 0.2500 - val_acc: 0.9335\n",
      "Epoch 37/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0979 - acc: 0.9627 - val_loss: 0.2449 - val_acc: 0.9367\n",
      "Epoch 38/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.0982 - acc: 0.9626 - val_loss: 0.2953 - val_acc: 0.9173\n",
      "Epoch 39/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.0955 - acc: 0.9648 - val_loss: 0.2615 - val_acc: 0.9321\n",
      "Epoch 40/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.0930 - acc: 0.9647 - val_loss: 0.2304 - val_acc: 0.9404\n",
      "Epoch 41/50\n",
      "28335/28335 [==============================] - 163s - loss: 0.0917 - acc: 0.9657 - val_loss: 0.2434 - val_acc: 0.9386\n",
      "Epoch 42/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0849 - acc: 0.9678 - val_loss: 0.2420 - val_acc: 0.9401\n",
      "Epoch 43/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.0921 - acc: 0.9653 - val_loss: 0.2390 - val_acc: 0.9406\n",
      "Epoch 44/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.0783 - acc: 0.9705 - val_loss: 0.2589 - val_acc: 0.9354\n",
      "Epoch 45/50\n",
      "28335/28335 [==============================] - 167s - loss: 0.0856 - acc: 0.9678 - val_loss: 0.2524 - val_acc: 0.9415\n",
      "Epoch 46/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.0818 - acc: 0.9695 - val_loss: 0.2605 - val_acc: 0.9341\n",
      "Epoch 47/50\n",
      "28335/28335 [==============================] - 159s - loss: 0.0799 - acc: 0.9694 - val_loss: 0.2660 - val_acc: 0.9400\n",
      "Epoch 48/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.0808 - acc: 0.9694 - val_loss: 0.2421 - val_acc: 0.9429\n",
      "Epoch 49/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.0822 - acc: 0.9688 - val_loss: 0.2596 - val_acc: 0.9329\n",
      "Epoch 50/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.0763 - acc: 0.9704 - val_loss: 0.2488 - val_acc: 0.9420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b06fc18>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val_acc: 0.9401\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=num_epochs, verbose=1, validation_data = (x_test, y_test), \n",
    "          class_weight= [1, 10, 5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_nn_model_save_dir = 'weather nn//'\n",
    "model_name = '50e + weights 1-10-5-2'\n",
    "\n",
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open(weather_nn_model_save_dir + model_name + \".json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n",
    "model.save_weights(weather_nn_model_save_dir + model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "анализ результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test_predicted = model.predict(x_test)\n",
    "x_test_real = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PredictMax(x):\n",
    "    x_predicted = np.zeros(x.shape)\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        ind = np.argmax(x[i, :])\n",
    "        x_predicted[i, ind] = 1\n",
    "    \n",
    "    return x_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfscore = 0\\n\\nfor tres in np.arange(0, 1, 0.01):\\n    cscore = AvgFBettaScore(x_test_real, x_test_predicted, treshold= float(tres))\\n    \\n    if cscore > fscore:\\n        fscore = cscore\\n        print(tres, fscore)\\n\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.09 0.9545518264947699\n",
    "# 0.1 0.9575716403162146 with weights\n",
    "'''\n",
    "fscore = 0\n",
    "\n",
    "for tres in np.arange(0, 1, 0.01):\n",
    "    cscore = AvgFBettaScore(x_test_real, x_test_predicted, treshold= float(tres))\n",
    "    \n",
    "    if cscore > fscore:\n",
    "        fscore = cscore\n",
    "        print(tres, fscore)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clear</th>\n",
       "      <td>8267</td>\n",
       "      <td>320</td>\n",
       "      <td>182</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudy</th>\n",
       "      <td>521</td>\n",
       "      <td>70</td>\n",
       "      <td>140</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haze</th>\n",
       "      <td>607</td>\n",
       "      <td>174</td>\n",
       "      <td>236</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partly_cloudy</th>\n",
       "      <td>2044</td>\n",
       "      <td>141</td>\n",
       "      <td>146</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tp   fp   fn   cnt\n",
       "clear          8267  320  182  8449\n",
       "cloudy          521   70  140   661\n",
       "haze            607  174  236   843\n",
       "partly_cloudy  2044  141  146  2190"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_binomial = PredictMax(x_test_predicted)\n",
    "\n",
    "errors = np.zeros((len(weather_cathegories), 4))\n",
    "\n",
    "for i in range(x_test_binomial.shape[0]):\n",
    "    for j in range(x_test_binomial.shape[1]):\n",
    "        predicted = x_test_binomial[i, j]\n",
    "        real = x_test_real[i, j]\n",
    "        \n",
    "        \n",
    "        if predicted == 1 and real == 1:\n",
    "            errors[j, 0] += 1\n",
    "        \n",
    "        if predicted == 1 and real == 0:\n",
    "            errors[j, 1] += 1\n",
    "        \n",
    "        if predicted == 0 and real == 1:\n",
    "            errors[j, 2] += 1\n",
    "        \n",
    "        if real == 1:\n",
    "            errors[j, 3] += 1\n",
    "\n",
    "errors = errors.astype(int)\n",
    "errors_df = pd.DataFrame(errors, index= weather_cathegories, columns= ['tp', 'fp', 'fn', 'cnt'])\n",
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clear</th>\n",
       "      <td>8354</td>\n",
       "      <td>460</td>\n",
       "      <td>95</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudy</th>\n",
       "      <td>607</td>\n",
       "      <td>152</td>\n",
       "      <td>54</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haze</th>\n",
       "      <td>687</td>\n",
       "      <td>370</td>\n",
       "      <td>156</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partly_cloudy</th>\n",
       "      <td>2080</td>\n",
       "      <td>189</td>\n",
       "      <td>110</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tp   fp   fn   cnt\n",
       "clear          8354  460   95  8449\n",
       "cloudy          607  152   54   661\n",
       "haze            687  370  156   843\n",
       "partly_cloudy  2080  189  110  2190"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_binomial = BinimialPrediction(x_test_predicted, treshold= 0.2)\n",
    "\n",
    "errors = np.zeros((len(weather_cathegories), 4))\n",
    "\n",
    "for i in range(x_test_binomial.shape[0]):\n",
    "    for j in range(x_test_binomial.shape[1]):\n",
    "        predicted = x_test_binomial[i, j]\n",
    "        real = x_test_real[i, j]\n",
    "        \n",
    "        \n",
    "        if predicted == 1 and real == 1:\n",
    "            errors[j, 0] += 1\n",
    "        \n",
    "        if predicted == 1 and real == 0:\n",
    "            errors[j, 1] += 1\n",
    "        \n",
    "        if predicted == 0 and real == 1:\n",
    "            errors[j, 2] += 1\n",
    "        \n",
    "        if real == 1:\n",
    "            errors[j, 3] += 1\n",
    "\n",
    "errors = errors.astype(int)\n",
    "errors_df = pd.DataFrame(errors, index= weather_cathegories, columns= ['tp', 'fp', 'fn', 'cnt'])\n",
    "errors_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
