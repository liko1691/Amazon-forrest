{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import cifar10 # subroutines for fetching the CIFAR-10 dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_dir = 'C:\\\\Users\\\\horch\\\\Desktop\\\\Data mining\\\\Kaggle Amazon Rainforest\\\\'\n",
    "train_dir = core_dir + 'train-jpg\\\\'\n",
    "test_dir = core_dir + 'test-jpg\\\\'\n",
    "\n",
    "cathegories = ['agriculture', 'artisinal_mine', 'bare_ground', \n",
    "                      'blooming', 'blow_down', 'clear', 'cloudy', 'conventional_mine', \n",
    "                      'cultivation', 'habitation', 'haze', 'partly_cloudy', 'primary', \n",
    "                      'road', 'selective_logging', 'slash_burn', 'water']\n",
    "\n",
    "train_data = pd.read_csv(core_dir + 'train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подготовка обучающей выборки по имени категории\n",
    "принимает категорию, возвращает массив из 0 и 1 (1 - файл содержит категорию, 0 - иначе)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TrainingSetByCathegory(cathegory):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['image_name'] = train_data.image_name.values\n",
    "    df['indicator'] = np.zeros(train_data.shape[0])\n",
    "    \n",
    "    df.loc[df['image_name'].isin(cathegory_dict[cathegory]), ['indicator']] = 1\n",
    "    \n",
    "    return df.indicator.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "функция предназначенная для конвертации .jpg изображения в numpy массив\n",
    "если transparency = False, то каждая точка представляется 3 числами иначе - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ImageToNumpy(img_name, img_dir = train_dir, img_type = '.jpg', transparency = False):\n",
    "    img = Image.open(train_dir + img_name + img_type)\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    img.close()\n",
    "    \n",
    "    if transparency:\n",
    "        return data\n",
    "    else:\n",
    "        return data[:, :, 0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ImgToNumpyNormal(img_to_numpy):\n",
    "    #im = Image.open(train_dir + img_name + img_type)\n",
    "    #im_grey = im.convert('L')\n",
    "    #im_array = np.array(im).astype('float32')\n",
    "    img_to_numpy /=np.max(img_to_numpy)\n",
    "    return img_to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычисления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создадим словарь категорий\n",
    "каждой категории будет соответствовать список файлов, в которых данная категория присутствует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cathegory_dict = {cathegory: [] for cathegory in cathegories}\n",
    "\n",
    "ind = 0\n",
    "for tag in train_data.tags.values:\n",
    "    file_name = train_data.image_name[ind]\n",
    "    \n",
    "    cathegory_names_list = tag.split(' ')\n",
    "    \n",
    "    for cathegory in cathegory_names_list:\n",
    "        cathegory_dict[cathegory].append(file_name)\n",
    "    \n",
    "    ind += 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "переведем все изображения в числовые массивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_1000=[]\n",
    "for img_name in train_data.image_name.values[0:1000]:\n",
    "    x_train_1000.append(ImageToNumpy(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_0\n",
      "train_1000\n",
      "train_2000\n",
      "train_3000\n",
      "train_4000\n",
      "train_5000\n",
      "train_6000\n"
     ]
    }
   ],
   "source": [
    "X = [None]*10000\n",
    "l = 0\n",
    "\n",
    "for img_name in train_data.image_name.values[0:10000]:\n",
    "    #X.append(ImageToNumpy(img_name, transparency = True))\n",
    "    X[l] = ImageToNumpy(img_name)\n",
    "    \n",
    "    if l % 1000 == 0:\n",
    "        print(img_name)\n",
    "    l += 1\n",
    "\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('int32') and format specifier ('%.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1157\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m                     \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-123763a0332e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpsavedir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageToNumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1160\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[0;32m   1161\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[0;32m   1163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('int32') and format specifier ('%.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e')"
     ]
    }
   ],
   "source": [
    "npsavedir = 'd:\\\\nptestdata\\\\'\n",
    "l = 0\n",
    "\n",
    "for img_name in train_data.image_name.values[0:1000]:\n",
    "    #np.savetxt(npsavedir+img_name, ImageToNumpy(img_name))\n",
    "    np.save(npsavedir+img_name, ImageToNumpy(img_name))\n",
    "    \n",
    "    if l % 1000 == 0:\n",
    "        print(img_name)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Сверточная нейросеть для одной категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256 # in each iteration, we consider 256 training examples at once\n",
    "num_epochs = 20 # we iterate 20 times over the entire training set\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 256 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 512 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 4096 # the FC layer will have 512 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88333333,  0.875     ,  0.875     ,  0.89166665,  0.91666669,\n",
       "        0.90833336,  0.875     ,  0.84166664,  0.875     ,  0.875     ,\n",
       "        0.875     ,  0.86666667,  0.85000002,  0.84166664,  0.84166664,\n",
       "        0.85000002,  0.88333333,  0.875     ,  0.85833335,  0.85000002,\n",
       "        0.85000002,  0.85000002,  0.83333331,  0.80000001,  0.80000001,\n",
       "        0.85000002,  0.91666669,  0.94999999,  0.94166666,  0.90833336,\n",
       "        0.86666667,  0.84166664,  0.875     ,  0.875     ,  0.89166665,\n",
       "        0.91666669,  0.91666669,  0.88333333,  0.85833335,  0.85000002,\n",
       "        0.85833335,  0.86666667,  0.875     ,  0.88333333,  0.875     ,\n",
       "        0.85833335,  0.84166664,  0.84166664,  0.84166664,  0.85833335,\n",
       "        0.875     ,  0.88333333,  0.86666667,  0.85833335,  0.875     ,\n",
       "        0.89999998,  0.88333333,  0.875     ,  0.85833335,  0.85000002,\n",
       "        0.85000002,  0.84166664,  0.84166664,  0.83333331,  0.88333333,\n",
       "        0.88333333,  0.86666667,  0.85833335,  0.84166664,  0.84166664,\n",
       "        0.85000002,  0.85000002,  0.88333333,  0.88333333,  0.875     ,\n",
       "        0.875     ,  0.875     ,  0.875     ,  0.875     ,  0.875     ,\n",
       "        0.85000002,  0.85000002,  0.85833335,  0.85833335,  0.85000002,\n",
       "        0.85833335,  0.875     ,  0.89166665,  0.875     ,  0.875     ,\n",
       "        0.89166665,  0.90833336,  0.91666669,  0.90833336,  0.89999998,\n",
       "        0.88333333,  0.86666667,  0.86666667,  0.86666667,  0.85833335,\n",
       "        0.84166664,  0.84166664,  0.85833335,  0.875     ,  0.85000002,\n",
       "        0.85000002,  0.86666667,  0.88333333,  0.90833336,  0.91666669,\n",
       "        0.90833336,  0.90833336,  0.85000002,  0.85000002,  0.84166664,\n",
       "        0.83333331,  0.85833335,  0.875     ,  0.875     ,  0.85833335,\n",
       "        0.84166664,  0.83333331,  0.83333331,  0.83333331,  0.83333331,\n",
       "        0.84166664,  0.85000002,  0.85833335,  0.88333333,  0.86666667,\n",
       "        0.85000002,  0.84166664,  0.85000002,  0.85833335,  0.85833335,\n",
       "        0.85833335,  0.85000002,  0.81666666,  0.79166669,  0.80833334,\n",
       "        0.83333331,  0.85000002,  0.86666667,  0.88333333,  0.83333331,\n",
       "        0.84166664,  0.84166664,  0.84166664,  0.82499999,  0.82499999,\n",
       "        0.84166664,  0.85000002,  0.80833334,  0.81666666,  0.82499999,\n",
       "        0.83333331,  0.85000002,  0.85833335,  0.85833335,  0.85000002,\n",
       "        0.84166664,  0.86666667,  0.88333333,  0.85833335,  0.83333331,\n",
       "        0.84166664,  0.85833335,  0.86666667,  0.88333333,  0.86666667,\n",
       "        0.84166664,  0.84166664,  0.85833335,  0.875     ,  0.88333333,\n",
       "        0.88333333,  0.85000002,  0.85000002,  0.85833335,  0.85000002,\n",
       "        0.85000002,  0.85000002,  0.85833335,  0.86666667,  0.85833335,\n",
       "        0.85000002,  0.85000002,  0.84166664,  0.85833335,  0.875     ,\n",
       "        0.875     ,  0.86666667,  0.875     ,  0.85000002,  0.82499999,\n",
       "        0.83333331,  0.84166664,  0.83333331,  0.83333331,  0.84166664,\n",
       "        0.875     ,  0.86666667,  0.85000002,  0.82499999,  0.80833334,\n",
       "        0.81666666,  0.84166664,  0.86666667,  0.84166664,  0.84166664,\n",
       "        0.85000002,  0.85000002,  0.85833335,  0.86666667,  0.85833335,\n",
       "        0.86666667,  0.85000002,  0.86666667,  0.875     ,  0.86666667,\n",
       "        0.85000002,  0.83333331,  0.84166664,  0.85000002,  0.80000001,\n",
       "        0.80000001,  0.81666666,  0.85833335,  0.89166665,  0.89166665,\n",
       "        0.86666667,  0.82499999,  0.85833335,  0.85833335,  0.85833335,\n",
       "        0.84166664,  0.82499999,  0.81666666,  0.81666666,  0.82499999,\n",
       "        0.875     ,  0.875     ,  0.875     ,  0.88333333,  0.875     ,\n",
       "        0.86666667,  0.85833335,  0.85833335,  0.81666666,  0.80833334,\n",
       "        0.80833334,  0.82499999,  0.86666667,  0.88333333,  0.875     ,\n",
       "        0.86666667], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "ImgToNumpyNormal(train_data.image_name[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка изображений и их приведение к подходящему для обработки виду\n",
    "y_train = TrainingSetByCathegory(cathegories[0]) #y_train labels (для категории_0 1, если подходит, 0-иначе)\n",
    "\n",
    "\n",
    "num_train = 40479\n",
    "depth = 256 \n",
    "height = 256\n",
    "width = 3 \n",
    "num_classes = len(cathegories)\n",
    "\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# непосредственно модель\n",
    "\n",
    "inp = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, nb_epoch=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
