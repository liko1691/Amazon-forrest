{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "определение категорий без маркеров погоды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PathDetermination(user):\n",
    "    if user == 'litvin_home':\n",
    "        core_dir = 'C:\\\\Kaggle\\\\Understanding the Amazon from Space\\\\'\n",
    "    \n",
    "    if user == 'litvin_office':\n",
    "        core_dir = 'D:\\\\Kaggle\\\\Understanding the Amazon from Space\\\\'\n",
    "        train_dir = core_dir + 'train-jpg\\\\'\n",
    "        test_dir = core_dir + 'test-jpg\\\\'\n",
    "        add_test_dir = core_dir + 'test-jpg-additional\\\\'\n",
    "    \n",
    "    if user == 'savina':\n",
    "        core_dir = 'Z:\\\\Kaggle Amazon Rainforest\\\\'\n",
    "        train_dir = ''\n",
    "        test_dir = 'C:\\\\Users\\\\horch\\\\Desktop\\\\Local_data\\\\test-jpg\\\\'\n",
    "        add_test_dir = 'C:\\\\Users\\\\horch\\\\Desktop\\\\Local_data\\\\test-jpg-additional\\\\'\n",
    "    \n",
    "    return core_dir, train_dir, test_dir, add_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_dir, train_dir, test_dir, add_test_dir = PathDetermination('litvin_office')\n",
    "#core_dir, test_dir, add_test_dir = path_determination('savina')\n",
    "\n",
    "test_data_names = natsorted(os.listdir(test_dir), key=lambda y: y.lower())\n",
    "add_test_data_names = os.listdir(add_test_dir)\n",
    "\n",
    "\n",
    "cathegories = ['agriculture', 'artisinal_mine', 'bare_ground', \n",
    "                      'blooming', 'blow_down', 'clear', 'cloudy', 'conventional_mine', \n",
    "                      'cultivation', 'habitation', 'haze', 'partly_cloudy', 'primary', \n",
    "                      'road', 'selective_logging', 'slash_burn', 'water']\n",
    "\n",
    "no_weather_cathegories = ['agriculture', 'artisinal_mine', 'bare_ground', \n",
    "                      'blooming', 'blow_down', 'conventional_mine', \n",
    "                      'cultivation', 'habitation', 'primary', \n",
    "                      'road', 'selective_logging', 'slash_burn', 'water']\n",
    "\n",
    "train_data = pd.read_csv(core_dir + 'train_v2.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BinimialPrediction(X, treshold = 0.5):\n",
    "    result = np.zeros(X.shape)\n",
    "    \n",
    "    if type(treshold) == int or type(treshold) == float:\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                if X[i, j] >= treshold:\n",
    "                    result[i, j] = 1\n",
    "    elif type(treshold) == list:\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                if X[i, j] >= treshold[j]:\n",
    "                    result[i, j] = 1\n",
    "    else:\n",
    "        print('treshold type must be int, float or list')\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "def FBettaScore(x_true, x_predicted, betta = 2):\n",
    "    if len(x_true) == len(x_predicted):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for i in range(len(x_predicted)):\n",
    "            if x_true[i] == 1 and x_predicted[i] == 1:\n",
    "                tp += 1\n",
    "            \n",
    "            if x_true[i] == 0 and x_predicted[i] == 1:\n",
    "                fp += 1\n",
    "            \n",
    "            if x_true[i] == 1 and x_predicted[i] == 0:\n",
    "                fn += 1\n",
    "        \n",
    "        if tp == 0 or (tp + fp) == 0 or (tp + fn) == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            precision = tp/(tp + fp)\n",
    "            recall = tp/(tp + fn)\n",
    "            \n",
    "            return((1 + betta**2)*precision*recall/(betta**2*precision + recall))\n",
    "    else:\n",
    "        print('FBettaScore error! len(x_true) != len(x_predicted)')\n",
    "\n",
    "def AvgFBettaScore(x_true, x_predicted, betta = 2, treshold = 0.5):\n",
    "    result = 0\n",
    "    n = x_true.shape[0]\n",
    "    \n",
    "    x_predicted = BinimialPrediction(x_predicted, treshold)\n",
    "    \n",
    "    for i in range(n):\n",
    "        result += FBettaScore(x_true[i, :], x_predicted[i, :], betta)\n",
    "    \n",
    "    return(result/n)\n",
    "\n",
    "def OptimalTreshold(x_predicted, x_real, current_treshold):\n",
    "\n",
    "    current_best_result = AvgFBettaScore(x_real, x_predicted, treshold = current_treshold) \n",
    "\n",
    "    random_sequence = np.random.choice(range(len(current_treshold)), len(current_treshold), replace= False)\n",
    "\n",
    "    for k in random_sequence:\n",
    "        for i in np.arange(0, 1.01, 0.01):\n",
    "            tr = current_treshold.copy()\n",
    "            tr[k] = i\n",
    "\n",
    "            current_result = AvgFBettaScore(x_real, x_predicted, treshold = tr)\n",
    "\n",
    "            if current_result > current_best_result:\n",
    "                current_best_result = current_result\n",
    "                current_treshold = tr\n",
    "\n",
    "        print(k, current_best_result, current_treshold)\n",
    "    \n",
    "    return(current_treshold, current_best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataPreperation(data_type, img_size = (32, 32), rotation = [0], \n",
    "                    test_img_dir = [test_dir, add_test_dir], shuffle = False):\n",
    "    if data_type == 'train':\n",
    "        X = []\n",
    "        Y = []\n",
    "        \n",
    "        for img_name in tqdm(train_data.image_name.values):\n",
    "    \n",
    "            img = cv2.imread(train_dir + img_name + '.jpg')\n",
    "            img_resized = cv2.resize(img, img_size)\n",
    "            \n",
    "            img_tags = train_data[train_data['image_name'] == img_name]['tags'].values[0].split(' ')\n",
    "            y = np.zeros(len(cathegories))\n",
    "            \n",
    "            for i in range(len(y)):\n",
    "                if cathegories[i] in img_tags:\n",
    "                    y[i] = 1\n",
    "            \n",
    "            for angle in rotation:\n",
    "                img = imutils.rotate(img_resized, angle)\n",
    "                X.append(img)\n",
    "                Y.append(y) \n",
    "        \n",
    "        X = np.array(X, np.float16) / 255.\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        if shuffle:\n",
    "            ind = np.random.choice(np.arange(X.shape[0]), X.shape[0], replace= False)\n",
    "            X = X[ind]\n",
    "            Y = Y[ind]\n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "    if data_type == 'test':\n",
    "        X_test = []\n",
    "        X_test_names = []\n",
    "\n",
    "        for img_dir in test_img_dir:\n",
    "            img_dir_names = os.listdir(img_dir)\n",
    "            \n",
    "            for img_name in tqdm(img_dir_names):\n",
    "                if img_name.endswith(\"jpg\"):\n",
    "                    img = cv2.imread(img_dir + img_name)\n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    \n",
    "                    X_test.append(img)\n",
    "                    X_test_names.append(img_name)\n",
    "    \n",
    "        X_test = np.array(X_test, np.float16) / 255.\n",
    "        \n",
    "        return X_test, X_test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 40479/40479 [11:57<00:00, 56.44it/s]\n"
     ]
    }
   ],
   "source": [
    "X, Y = DataPreperation('train', rotation = [0], shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_no_weather = Y[:, [cathegories.index(x) for x in no_weather_cathegories]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits= 1, test_size= 0.3, random_state= 42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, Y_no_weather):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_no_weather[train_index], Y_no_weather[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка и  обучение сети для погоды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 64\n",
    "drop_prob_1 = 0.25\n",
    "drop_prob_2 = 0.5\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train = X.shape[0]\n",
    "depth = 32 \n",
    "height = 32\n",
    "width = 3 \n",
    "\n",
    "num_classes = len(no_weather_cathegories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras!\n",
    "\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "\n",
    "flat = Flatten()(drop_2)\n",
    "\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "\n",
    "out = Dense(num_classes, activation='sigmoid')(drop_3)\n",
    "\n",
    "model = Model(input=inp, output=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28335 samples, validate on 12144 samples\n",
      "Epoch 1/50\n",
      "28335/28335 [==============================] - 169s - loss: 0.2078 - acc: 0.9217 - val_loss: 0.1794 - val_acc: 0.9276\n",
      "Epoch 2/50\n",
      "28335/28335 [==============================] - 176s - loss: 0.1748 - acc: 0.9321 - val_loss: 0.1680 - val_acc: 0.9358\n",
      "Epoch 3/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.1627 - acc: 0.9358 - val_loss: 0.1539 - val_acc: 0.9401\n",
      "Epoch 4/50\n",
      "28335/28335 [==============================] - 168s - loss: 0.1560 - acc: 0.9382 - val_loss: 0.1461 - val_acc: 0.9417\n",
      "Epoch 5/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.1502 - acc: 0.9401 - val_loss: 0.1443 - val_acc: 0.9429\n",
      "Epoch 6/50\n",
      "28335/28335 [==============================] - 168s - loss: 0.1462 - acc: 0.9417 - val_loss: 0.1426 - val_acc: 0.9427\n",
      "Epoch 7/50\n",
      "28335/28335 [==============================] - 175s - loss: 0.1419 - acc: 0.9435 - val_loss: 0.1363 - val_acc: 0.9456\n",
      "Epoch 8/50\n",
      "28335/28335 [==============================] - 165s - loss: 0.1376 - acc: 0.9449 - val_loss: 0.1320 - val_acc: 0.9467\n",
      "Epoch 9/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1351 - acc: 0.9459 - val_loss: 0.1307 - val_acc: 0.9474\n",
      "Epoch 10/50\n",
      "28335/28335 [==============================] - 165s - loss: 0.1320 - acc: 0.9473 - val_loss: 0.1289 - val_acc: 0.9483\n",
      "Epoch 11/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.1297 - acc: 0.9482 - val_loss: 0.1335 - val_acc: 0.9464\n",
      "Epoch 12/50\n",
      "28335/28335 [==============================] - 163s - loss: 0.1252 - acc: 0.9500 - val_loss: 0.1231 - val_acc: 0.9511\n",
      "Epoch 13/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.1215 - acc: 0.9514 - val_loss: 0.1228 - val_acc: 0.9514\n",
      "Epoch 14/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.1180 - acc: 0.9529 - val_loss: 0.1204 - val_acc: 0.9523\n",
      "Epoch 15/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.1151 - acc: 0.9540 - val_loss: 0.1247 - val_acc: 0.9516\n",
      "Epoch 16/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.1113 - acc: 0.9556 - val_loss: 0.1172 - val_acc: 0.9543\n",
      "Epoch 17/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.1073 - acc: 0.9573 - val_loss: 0.1162 - val_acc: 0.9552\n",
      "Epoch 18/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.1042 - acc: 0.9587 - val_loss: 0.1137 - val_acc: 0.9561\n",
      "Epoch 19/50\n",
      "28335/28335 [==============================] - 160s - loss: 0.1013 - acc: 0.9597 - val_loss: 0.1121 - val_acc: 0.9571\n",
      "Epoch 20/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0983 - acc: 0.9611 - val_loss: 0.1121 - val_acc: 0.9572\n",
      "Epoch 21/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.0945 - acc: 0.9629 - val_loss: 0.1079 - val_acc: 0.9594\n",
      "Epoch 22/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.0920 - acc: 0.9639 - val_loss: 0.1083 - val_acc: 0.9599\n",
      "Epoch 23/50\n",
      "28335/28335 [==============================] - 169s - loss: 0.0881 - acc: 0.9652 - val_loss: 0.1050 - val_acc: 0.9617\n",
      "Epoch 24/50\n",
      "28335/28335 [==============================] - 174s - loss: 0.0854 - acc: 0.9667 - val_loss: 0.1067 - val_acc: 0.9623\n",
      "Epoch 25/50\n",
      "28335/28335 [==============================] - 174s - loss: 0.0829 - acc: 0.9674 - val_loss: 0.1081 - val_acc: 0.9621\n",
      "Epoch 26/50\n",
      "28335/28335 [==============================] - 174s - loss: 0.0809 - acc: 0.9683 - val_loss: 0.1056 - val_acc: 0.9628\n",
      "Epoch 27/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.0777 - acc: 0.9697 - val_loss: 0.1050 - val_acc: 0.9632\n",
      "Epoch 28/50\n",
      "28335/28335 [==============================] - 152s - loss: 0.0751 - acc: 0.9711 - val_loss: 0.1050 - val_acc: 0.9652\n",
      "Epoch 29/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.0721 - acc: 0.9716 - val_loss: 0.1035 - val_acc: 0.9646\n",
      "Epoch 30/50\n",
      "28335/28335 [==============================] - 168s - loss: 0.0699 - acc: 0.9728 - val_loss: 0.1057 - val_acc: 0.9661\n",
      "Epoch 31/50\n",
      "28335/28335 [==============================] - 165s - loss: 0.0681 - acc: 0.9736 - val_loss: 0.1061 - val_acc: 0.9655\n",
      "Epoch 32/50\n",
      "28335/28335 [==============================] - 171s - loss: 0.0672 - acc: 0.9739 - val_loss: 0.1027 - val_acc: 0.9672\n",
      "Epoch 33/50\n",
      "28335/28335 [==============================] - 169s - loss: 0.0641 - acc: 0.9750 - val_loss: 0.1041 - val_acc: 0.9672\n",
      "Epoch 34/50\n",
      "28335/28335 [==============================] - 166s - loss: 0.0628 - acc: 0.9757 - val_loss: 0.1052 - val_acc: 0.9676\n",
      "Epoch 35/50\n",
      "28335/28335 [==============================] - 164s - loss: 0.0608 - acc: 0.9766 - val_loss: 0.1022 - val_acc: 0.9684\n",
      "Epoch 36/50\n",
      "28335/28335 [==============================] - 163s - loss: 0.0605 - acc: 0.9769 - val_loss: 0.1027 - val_acc: 0.9691\n",
      "Epoch 37/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.0599 - acc: 0.9769 - val_loss: 0.1094 - val_acc: 0.9679\n",
      "Epoch 38/50\n",
      "28335/28335 [==============================] - 171s - loss: 0.0562 - acc: 0.9781 - val_loss: 0.1032 - val_acc: 0.9695\n",
      "Epoch 39/50\n",
      "28335/28335 [==============================] - 175s - loss: 0.0557 - acc: 0.9784 - val_loss: 0.1023 - val_acc: 0.9694\n",
      "Epoch 40/50\n",
      "28335/28335 [==============================] - 171s - loss: 0.0537 - acc: 0.9793 - val_loss: 0.1033 - val_acc: 0.9686\n",
      "Epoch 41/50\n",
      "28335/28335 [==============================] - 174s - loss: 0.0529 - acc: 0.9796 - val_loss: 0.1050 - val_acc: 0.9693\n",
      "Epoch 42/50\n",
      "28335/28335 [==============================] - 170s - loss: 0.0524 - acc: 0.9794 - val_loss: 0.1059 - val_acc: 0.9692\n",
      "Epoch 43/50\n",
      "28335/28335 [==============================] - 170s - loss: 0.0510 - acc: 0.9801 - val_loss: 0.1084 - val_acc: 0.9682\n",
      "Epoch 44/50\n",
      "28335/28335 [==============================] - 170s - loss: 0.0497 - acc: 0.9810 - val_loss: 0.1057 - val_acc: 0.9696\n",
      "Epoch 45/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0490 - acc: 0.9810 - val_loss: 0.1057 - val_acc: 0.9711\n",
      "Epoch 46/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0474 - acc: 0.9816 - val_loss: 0.1044 - val_acc: 0.9706\n",
      "Epoch 47/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0462 - acc: 0.9819 - val_loss: 0.1049 - val_acc: 0.9715\n",
      "Epoch 48/50\n",
      "28335/28335 [==============================] - 161s - loss: 0.0452 - acc: 0.9825 - val_loss: 0.1067 - val_acc: 0.9711\n",
      "Epoch 49/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.0459 - acc: 0.9823 - val_loss: 0.1052 - val_acc: 0.9703\n",
      "Epoch 50/50\n",
      "28335/28335 [==============================] - 162s - loss: 0.0443 - acc: 0.9830 - val_loss: 0.1023 - val_acc: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfd49da0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=num_epochs, verbose=1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_nn_model_save_dir = 'weather nn//'\n",
    "model_name = 'no_weather 50e'\n",
    "\n",
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open(weather_nn_model_save_dir + model_name + \".json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n",
    "model.save_weights(weather_nn_model_save_dir + model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "анализ результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test_predicted = model.predict(x_test)\n",
    "x_test_real = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "12 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "10 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "2 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "7 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "8 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "4 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "9 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "6 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "1 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "0 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "3 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
      "5 0.8777174093248922 [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n"
     ]
    }
   ],
   "source": [
    "#initial_treshold = 0.24\n",
    "initial_treshold = [0.23, 0.34, 0.27, 0.14, 0.17, 0.24, 0.22, 0.25, 0.0, 0.35, 0.25, 0.46, 0.17]\n",
    "\n",
    "optimat_treshold, optimal_treshold_result = OptimalTreshold(x_test_predicted, y_test, initial_treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agriculture</th>\n",
       "      <td>3441</td>\n",
       "      <td>726</td>\n",
       "      <td>236</td>\n",
       "      <td>3677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artisinal_mine</th>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare_ground</th>\n",
       "      <td>163</td>\n",
       "      <td>90</td>\n",
       "      <td>104</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blooming</th>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blow_down</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventional_mine</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultivation</th>\n",
       "      <td>937</td>\n",
       "      <td>511</td>\n",
       "      <td>337</td>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitation</th>\n",
       "      <td>823</td>\n",
       "      <td>350</td>\n",
       "      <td>277</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary</th>\n",
       "      <td>11117</td>\n",
       "      <td>325</td>\n",
       "      <td>56</td>\n",
       "      <td>11173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>2161</td>\n",
       "      <td>815</td>\n",
       "      <td>264</td>\n",
       "      <td>2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selective_logging</th>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slash_burn</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>1789</td>\n",
       "      <td>739</td>\n",
       "      <td>460</td>\n",
       "      <td>2249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tp   fp   fn    cnt\n",
       "agriculture         3441  726  236   3677\n",
       "artisinal_mine        55   11   19     74\n",
       "bare_ground          163   90  104    267\n",
       "blooming              44   15   49     93\n",
       "blow_down             17    1   11     28\n",
       "conventional_mine     12    0   12     24\n",
       "cultivation          937  511  337   1274\n",
       "habitation           823  350  277   1100\n",
       "primary            11117  325   56  11173\n",
       "road                2161  815  264   2425\n",
       "selective_logging     64   15   44    108\n",
       "slash_burn            27   11   23     50\n",
       "water               1789  739  460   2249"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_binomial = BinimialPrediction(x_test_predicted, treshold= 0.24)\n",
    "\n",
    "errors = np.zeros((len(no_weather_cathegories), 4))\n",
    "\n",
    "for i in range(x_test_binomial.shape[0]):\n",
    "    for j in range(x_test_binomial.shape[1]):\n",
    "        predicted = x_test_binomial[i, j]\n",
    "        real = x_test_real[i, j]\n",
    "        \n",
    "        \n",
    "        if predicted == 1 and real == 1:\n",
    "            errors[j, 0] += 1\n",
    "        \n",
    "        if predicted == 1 and real == 0:\n",
    "            errors[j, 1] += 1\n",
    "        \n",
    "        if predicted == 0 and real == 1:\n",
    "            errors[j, 2] += 1\n",
    "        \n",
    "        if real == 1:\n",
    "            errors[j, 3] += 1\n",
    "\n",
    "errors = errors.astype(int)\n",
    "errors_df = pd.DataFrame(errors, index= no_weather_cathegories, columns= ['tp', 'fp', 'fn', 'cnt'])\n",
    "errors_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
